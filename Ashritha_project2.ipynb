{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b348ef6d-d462-4ed3-9660-3f77643b44ea",
   "metadata": {},
   "source": [
    "# Module 9 Project 2\n",
    "### by Ashritha Reddy Devarampally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac1284-76b6-4de1-8c58-cc718b94c797",
   "metadata": {},
   "source": [
    "# XML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f851af-c1a9-476a-b37b-05a9c198cf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       loc                    lastmod  \\\n",
      "0      https://befound.pt/post-sitemap.xml  2021-09-14T10:16:33+00:00   \n",
      "1      https://befound.pt/page-sitemap.xml  2023-10-30T08:26:13+00:00   \n",
      "2  https://befound.pt/category-sitemap.xml  2021-09-14T10:16:33+00:00   \n",
      "3  https://befound.pt/post_tag-sitemap.xml  2021-09-14T10:16:33+00:00   \n",
      "4    https://befound.pt/author-sitemap.xml  2020-08-18T12:07:40+00:00   \n",
      "\n",
      "                                                data  \n",
      "0                                                 []  \n",
      "1  [{'loc': 'https://befound.pt/', 'lastmod': '20...  \n",
      "2  [{'loc': 'https://befound.pt/category/uncatego...  \n",
      "3  [{'loc': 'https://befound.pt/tag/seo-2020/', '...  \n",
      "4  [{'loc': 'https://befound.pt/author/sam/', 'la...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from task1 import SitemapParser\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    robots_url = \"https://befound.pt/robots.txt\"\n",
    "\n",
    "    crawler = SitemapParser(robots_url)\n",
    "    df = crawler.parse()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74300867-10a1-4d9e-ab32-96e504bf6087",
   "metadata": {},
   "source": [
    "# Using an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe293eab-a1de-4160-abbd-823b270da36c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'crossref'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrossref\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrestful\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Works\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtask2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossRefDatasetAPI\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'crossref'"
     ]
    }
   ],
   "source": [
    "from crossref.restful import Works\n",
    "from task2 import CrossRefDatasetAPI\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = CrossRefDatasetAPI(return_df=True)\n",
    "    df = dataset.query(bibliographic='zika', author='johannes', publisher_name='Wiley-Blackwell')\n",
    "    print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e060f-1b59-4523-9131-9c6034de0e9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa1b6df-3681-459f-8374-9eaf068f034f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreyashvenkata/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.nationmaster.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from task3 import BeautifulSoupScraper\n",
    "\n",
    "import pandas as pd\n",
    "if __name__ == '__main__':\n",
    "    bss = BeautifulSoupScraper()\n",
    "    df = bss.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be427626-0c37-4057-9298-f04b50967f2d",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa4f3dc-22bd-4733-9ae2-f026af373702",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreyashvenkata/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.nationmaster.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top Countries': [{'COUNTRY': 'Lebanon', 'AMOUNT': 1000000.0}, {'COUNTRY': 'Haiti', 'AMOUNT': 1000000.0}, {'COUNTRY': 'Afghanistan', 'AMOUNT': 1000000.0}, {'COUNTRY': 'Puerto Rico', 'AMOUNT': 1000000.0}, {'COUNTRY': 'Estonia', 'AMOUNT': 969700.0}], 'Average Users': 110390.47497991966, 'Num Above Average Countries': 60}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from task3 import BeautifulSoupScraper\n",
    "from task4 import InternetUsersAnalyzer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bss = BeautifulSoupScraper()\n",
    "    df = bss.parse()\n",
    "    analyzer = InternetUsersAnalyzer(df)\n",
    "    results = analyzer.analyse()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e9f49-ee6c-4e11-b0b2-264380f38b82",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Objective:\n",
    "The code aims to analyze internet users' data from a DataFrame, extracting insights such as the top countries with the highest internet users, the average number of internet users across all countries, and the number of countries with internet users above the average.\n",
    "\n",
    "2. Code Structure:\n",
    "\n",
    "The code is organized into a class named InternetUsersAnalyzer, encapsulating the analysis functionality.\n",
    "The class has two methods: _init_ and analyse.\n",
    "The _init_ method initializes the analyzer with a provided DataFrame containing internet users' data.\n",
    "The analyse method performs three analyses on the data and returns the results in a dictionary format.\n",
    "3. Data Processing:\n",
    "\n",
    "The 'AMOUNT' column in the DataFrame is preprocessed to extract numeric values and convert them to float, representing internet users in millions.\n",
    "4. Analyses:\n",
    "\n",
    "Analysis 1 (Top 5 Countries):\n",
    "\n",
    "Identifies and retrieves the top 5 countries with the highest number of internet users in millions.\n",
    "Analysis 2 (Average Users):\n",
    "\n",
    "Calculates the average number of internet users across all countries.\n",
    "Analysis 3 (Countries Above Average):\n",
    "\n",
    "Determines the number of countries with internet users above the calculated average.\n",
    "5. Results:\n",
    "\n",
    "The results of the analyses are stored in a dictionary named results.\n",
    "It includes information on the top countries, average users, and the number of countries above the average.\n",
    "6. Code Execution:\n",
    "\n",
    "The code uses an instance of the BeautifulSoupScraper class to fetch and parse internet users' data from a website.\n",
    "The InternetUsersAnalyzer is then instantiated with the obtained DataFrame, and the analyse method is called to generate results.\n",
    "7. Output:\n",
    "\n",
    "The final results are printed, providing insights into the top countries with the highest internet users, average users, and the count of countries with internet users above the average.\n",
    "8. Conclusion:\n",
    "\n",
    "The code successfully analyzes internet users' data and presents meaningful insights.\n",
    "It demonstrates effective utilization of pandas for data manipulation and analysis.\n",
    "The class-based structure enhances code organization and reusability.\n",
    "9. Suggestions for Improvement:\n",
    "\n",
    "Add error handling to gracefully handle potential issues during data fetching and analysis.\n",
    "Consider incorporating visualizations to enhance the presentation of analysis results.\n",
    "10. Overall Assessment:\n",
    "\n",
    "The code fulfills its intended purpose, providing valuable analyses on internet users' data.\n",
    "It adheres to good coding practices and demonstrates proficiency in working with pandas for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11782006-fc3c-4436-93f1-9d791b106c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
